import streamlit as st
from openai import OpenAI

# Read the system prompt from the external file
with open("sys_prompt.txt", "r", encoding="utf-8") as file:
    sys_prompt = file.read()

st.set_page_config(page_title="æ•™æœƒAIåŠ©æ‰‹", page_icon="âœï¸")

# Show title and description.
st.title("âœï¸  æ•™æœƒAIåŠ©æ‰‹ ")
st.warning("æ¸¬è©¦éšæ®µ", icon="âš ï¸")

if st.button("æ…¶ç¥ï¼ğŸ¥³"):
    st.balloons()


st.write("""
- å¯ä»¥å•æ•™æœƒè³‡è¨Š(è³‡è¨Šæˆªè‡³ 2025/01/12)
- å¯ä»¥ç”¢ç”Ÿå°çµ„æˆé•·é¡Œç›®
- å¯ä»¥è©¢å•å¦‚ä½•è®€è–ç¶“
""")

# Create an OpenAI client.
client = OpenAI(
    api_key="sk-c155cb6974f1429e879d54b117e3befb", base_url="https://api.deepseek.com"
)
model_name = "deepseek-chat"

# Create a session state variable to store the chat messages. This ensures that the
# messages persist across reruns.
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": sys_prompt}
    ]  # Add the system prompt here

# Display the existing chat messages via `st.chat_message`, excluding the system prompt
for message in st.session_state.messages:
    if message["role"] != "system":  # Skip the system prompt
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# Create a chat input field to allow the user to enter a message. This will display
# automatically at the bottom of the page.
if prompt := st.chat_input("å¹³å®‰ï¼æˆ‘èƒ½å”åŠ©ä½ ä»€éº¼ï¼Ÿ"):
    st.session_state.messages.append({"role": "user", "content": f"{prompt}"})
    st.chat_message("user").write(prompt)

    # Start streaming response
    response = client.chat.completions.create(
        model=model_name, messages=st.session_state.messages, stream=True
    )
    msg = ""
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        for chunk in response:  # Stream the response chunks
            chunk_content = (
                chunk.choices[0].delta.content
                if hasattr(chunk.choices[0].delta, "content")
                else ""
            )
            msg += chunk_content
            message_placeholder.markdown(msg)  # Update content incrementally
    st.session_state.messages.append({"role": "assistant", "content": msg})
